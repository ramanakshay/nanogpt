# training
max_iters: 600000

# optimizer
lr: 6e-4
weight_decay: 1e-1
betas: [0.9, 0.95]
eps: 1e-8

# norm
grad_clip: 1.0

# scheduler
decay_lr: True # whether to decay the learning rate
warmup_iters: 2000 # how many steps to warm up for
lr_decay_iters: ${max_iters} # should be ~= max_iters per Chinchilla
min_lr: 0.1 * ${algorithm.lr} # minimum learning rate, should be ~= learning_rate/10 per Chinchilla