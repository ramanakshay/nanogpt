from_pretrained: False
model_name: None
block_size: 1024
vocab_size: 50304 # GPT-2 vocab_size of 50257, padded up to nearest multiple of 64 for efficiency
n_layer: 12
n_head: 12
n_embd: 768
dropout: 0.0
bias: True